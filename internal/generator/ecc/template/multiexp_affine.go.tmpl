{{ $G1TAffine := print (toUpper .G1.PointName) "Affine" }}
{{ $G1TJacobian := print (toUpper .G1.PointName) "Jac" }}
{{ $G1TJacobianExtended := print (toLower .G1.PointName) "JacExtended" }}

{{ $G2TAffine := print (toUpper .G2.PointName) "Affine" }}
{{ $G2TJacobian := print (toUpper .G2.PointName) "Jac" }}
{{ $G2TJacobianExtended := print (toLower .G2.PointName) "JacExtended" }}


const MAX_BATCH_SIZE = 600

type batchOp struct {
	bucketID, pointID uint32
}

func (o batchOp) isNeg() bool {
	return o.pointID&1 == 1
}



{{ template "multiexp" dict "PointName" .G1.PointName "UPointName" (toUpper .G1.PointName) "TAffine" $G1TAffine "TJacobian" $G1TJacobian "TJacobianExtended" $G1TJacobianExtended "FrNbWords" .Fr.NbWords "CRange" .G1.CRange "LastCRange" .G1.LastCRange}}
{{ template "multiexp" dict "PointName" .G2.PointName "UPointName" (toUpper .G2.PointName) "TAffine" $G2TAffine "TJacobian" $G2TJacobian "TJacobianExtended" $G2TJacobianExtended "FrNbWords" .Fr.NbWords "CRange" .G2.CRange "LastCRange" .G2.LastCRange}}



{{define "multiexp" }}


// processChunk{{ $.UPointName }}BatchAffine process a chunk of the scalars during the msm
// using affine coordinates for the buckets. To amortize the cost of the inverse in the affine addition
// we use a batch affine addition.
// 
// this is derived from a PR by 0x0ece : https://github.com/ConsenSys/gnark-crypto/pull/249
// See Section 5.3: ia.cr/2022/1396
func processChunk{{ $.UPointName }}BatchAffine[B ib{{ $.TAffine }}, BS bitSet](chunk uint64,
	 chRes chan<- {{ $.TJacobianExtended }},
	 c uint64,
	 points []{{ $.TAffine }},
	 digits []uint32) {

	// init the buckets
	var buckets B
	for i := 0; i < len(buckets); i++ {
		buckets[i].setInfinity()
	}

	// setup for the batch affine;
	// we do that instead of a separate object to give enough hints to the compiler to..
	// keep things on the stack.
	batchSize := len(buckets) / 20
	if batchSize > MAX_BATCH_SIZE {
		batchSize = MAX_BATCH_SIZE
	}
	if batchSize <= 0 {
		batchSize = 1
	}
	var bucketIds BS // bitSet to signify presence of a bucket in current batch
	cptAdd := 0 // count the number of bucket + point added to current batch
	cptSub := 0 // count the number of bucket - point added to current batch

	var P [MAX_BATCH_SIZE]*{{ $.TAffine }} // points to be added to R (buckets)
	var R [MAX_BATCH_SIZE]*{{ $.TAffine }} // bucket references

	canAdd := func(bID uint32) bool {
		return !bucketIds[bID]
	}

	isFull := func() bool {
		return (cptAdd+cptSub) == batchSize
	}

	executeAndReset := func ()  {
		if (cptAdd+cptSub) == 0 {
			return
		}
		batchAdd{{ $.TAffine }}(R[:batchSize], P[:batchSize], cptAdd, cptSub)
		
		var tmp BS
		bucketIds = tmp
		cptAdd = 0
		cptSub = 0
	}

	add := func(op batchOp) {
		// CanAdd must be called before --> ensures bucket is not "used" in current batch
	
		BK := &buckets[op.bucketID]
		PP := &points[op.pointID>>1]
		if PP.IsInfinity() {
			return
		}
		// handle special cases with inf or -P / P
		if BK.IsInfinity() {
			if op.isNeg() {
				BK.Neg(PP)
			} else {
				BK.Set(PP)
			}
			return
		}
		if BK.X.Equal(&PP.X) {
			if BK.Y.Equal(&PP.Y) {
				if op.isNeg() {
					// P + -P
					BK.setInfinity()
					return
				}
				// P + P: doubling, which should be quite rare -- may want to put it back in the batch add?
				// TODO FIXME @gbotrel / @yelhousni this path is not taken by our tests.
				// need doubling in affine implemented ?
				BK.Add(BK, BK)
				return
			}
			// b.Y == -p.Y
			if op.isNeg() {
				// doubling . 
				BK.Add(BK, BK)
				return
			}
			BK.setInfinity()
			return
		}
		
	
		bucketIds[op.bucketID] = true
		if op.isNeg() {
			cptSub++
			R[batchSize - cptSub] = BK
			P[batchSize - cptSub] = PP
		} else {
			R[cptAdd] = BK
			P[cptAdd] = PP
			cptAdd++
		}
		
	}
	

	var queue [MAX_BATCH_SIZE]batchOp
	qID := 0

	processQueue := func () {
		for i := qID - 1; i >= 0; i-- {
			if canAdd(queue[i].bucketID) {
				add(queue[i])
				if isFull() {
					executeAndReset()
				}
				queue[i] = queue[qID-1]
				qID--
			}
		}
	}

	processTopQueue := func() {
		for i := qID - 1; i >= 0; i-- {
			if !canAdd(queue[i].bucketID) {
				return
			}
			add(queue[i])
			if isFull() {
				executeAndReset()
			}
			qID--
		}
	}

	for i, digit := range digits {

		if digit == 0 {
			continue
		}

		op := batchOp{pointID: uint32(i) << 1}
		// if msbWindow bit is set, we need to substract
		if digit&1 == 0 {
			// add
			op.bucketID = uint32((digit>>1) - 1)
		} else {
			// sub
			op.bucketID = (uint32((digit>>1)))
			op.pointID += 1
		}
		if canAdd(op.bucketID) {
			add(op)
			if isFull() {
				executeAndReset()
				processTopQueue()
			}
		} else {
			// put it in queue.
			queue[qID] = op 
			qID++
			if qID == MAX_BATCH_SIZE - 1 {
				executeAndReset()
				processQueue()
			}
			// queue = append(queue, op)
		}
	}

	for qID != 0 {
		processQueue()
		executeAndReset() // execute batch even if not full.
	}

	// flush items in batch.
	executeAndReset()

	// reduce buckets into total
	// total =  bucket[0] + 2*bucket[1] + 3*bucket[2] ... + n*bucket[n-1]

	var runningSum, total {{ $.TJacobianExtended }}
	runningSum.setInfinity()
	total.setInfinity()
	for k := len(buckets) - 1; k >= 0; k-- {
		if !buckets[k].IsInfinity() {
			runningSum.addMixed(&buckets[k])
		}
		total.add(&runningSum)
	}

	chRes <- total

}

// we declare the buckets as fixed-size array types
// this allow us to allocate the buckets on the stack
{{- range $c :=  $.CRange}}
type bucket{{ $.TAffine }}C{{$c}} [1<<({{$c}}-1)]{{ $.TAffine }}
{{- end}}

type ib{{ $.TAffine }} interface {
	{{- range $i, $c :=  $.CRange}}
	bucket{{ $.TAffine }}C{{$c}} {{- if not (last $i $.CRange)}} | {{- end}}
	{{- end}}
}

{{end }}

{{- range $c :=  $.G1.CRange}}
type bitSetC{{$c}} [1<<({{$c}}-1)]bool
{{- end}}

type bitSet interface {
	{{- range $i, $c :=  $.G1.CRange}}
	bitSetC{{$c}} {{- if not (last $i $.G1.CRange)}} | {{- end}}
	{{- end}}
}
